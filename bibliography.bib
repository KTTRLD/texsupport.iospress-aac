% This file was created with Citavi 6.7.0.0

@article{Caban.2015,
 author = {Caban, Jesus J. and Gotz, David},
 year = {2015},
 title = {Visual analytics in healthcare--opportunities and research challenges},
 pages = {260--262},
 volume = {22},
 number = {2},
 journal = {Journal of the American Medical Informatics Association : JAMIA},
 doi = {10.1093/jamia/ocv006},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/25814539}
}


@article{Weinberg.2010,
 author = {Weinberg, Robert},
 year = {2010},
 title = {Point: Hypotheses first},
 pages = {678},
 volume = {464},
 number = {7289},
 journal = {Nature},
 doi = {10.1038/464678a},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/20360718}
}


@article{Vlachavas.2021,
 author = {Vlachavas, Efstathios Iason and Bohn, Jonas and {\"U}ckert, Frank and N{\"u}rnberg, Sylvia},
 year = {2021},
 title = {A Detailed Catalogue of Multi-Omics Methodologies for Identification of Putative Biomarkers and Causal Molecular Networks in Translational Cancer Research},
 pages = {2822},
 volume = {22},
 number = {6},
 journal = {International Journal of Molecular Sciences},
 doi = {10.3390/ijms22062822},
 file = {Vlachavas, Bohn et al. 2021 - A Detailed Catalogue of Multi-Omics:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Vlachavas, Bohn et al. 2021 - A Detailed Catalogue of Multi-Omics.pdf:pdf}
}


@article{Stothers.2020,
 abstract = {Our current big data landscape prompts us to develop new analytical skills in order to make the best use of the abundance of datasets at hand. Traditionally, SQL databases such as PostgreSQL have been the databases of choice, and newer graph databases such as Neo4j have been relegated to the analysis of social network and transportation datasets. In this paper, we conduct a side by side comparison of PostgreSQL (using SQL) and Neo4j (using Cypher) using the MIMIC-III patient database as a case study. We found that, while Neo4j is more time intensive to implement, its queries are less complex and have a faster runtime than comparable queries performed in PostgreSQL. This leads to the conclusion that while PostgreSQL is adequate as a database, Neo4j should be considered a viable contender for health data storage and analysis.},
 author = {Stothers, Jessica A. M. and Nguyen, Andrew},
 year = {2020},
 title = {Can Neo4j Replace PostgreSQL in Healthcare?},
 pages = {646--653},
 volume = {2020},
 journal = {AMIA Summits on Translational Science Proceedings},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233060},
 file = {Stothers, Nguyen 2020 - Can Neo4j Replace PostgreSQL:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Stothers, Nguyen 2020 - Can Neo4j Replace PostgreSQL.pdf:pdf}
}


@article{Lysenko.2016,
 abstract = {BACKGROUND

Systems biology experiments generate large volumes of data of multiple modalities and this information presents a challenge for integration due to a mix of complexity together with rich semantics. Here, we describe how graph databases provide a powerful framework for storage, querying and envisioning of biological data.

RESULTS

We show how graph databases are well suited for the representation of biological information, which is typically highly connected, semi-structured and unpredictable. We outline an application case that uses the Neo4j graph database for building and querying a prototype network to provide biological context to asthma related genes.

CONCLUSIONS

Our study suggests that graph databases provide a flexible solution for the integration of multiple types of biological data and facilitate exploratory data mining to support hypothesis generation.},
 author = {Lysenko, Artem and Roznovăţ, Irina A. and Saqi, Mansoor and Mazein, Alexander and Rawlings, Christopher J. and Auffray, Charles},
 year = {2016},
 title = {Representing and querying disease networks using graph databases},
 pages = {23},
 volume = {9},
 issn = {1756-0381},
 journal = {BioData mining},
 doi = {10.1186/s13040-016-0102-8.},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4960687},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/27462371}
}


@misc{Johnson.2020,
 abstract = {MIMIC-III is a large, freely-available database comprising deidentified

health-related data associated with over forty thousand patients who stayed in

critical care units of the Beth Israel Deaconess Medical Center between 2001

and 2012. The database includes information such as demographics, vital sign

measurements made at the bedside ({\~{}}1 data point per hour), laboratory test

results, procedures, medications, caregiver notes, imaging reports, and

mortality (including post-hospital discharge).

MIMIC supports a diverse range of analytic studies spanning epidemiology,

clinical decision-rule improvement, and electronic tool development. It is

notable for three factors: it is freely available to researchers worldwide; it

encompasses a diverse and very large population of ICU patients; and it

contains highly granular data, including vital signs, laboratory results, and

medications.},
 author = {Johnson, Alistair and Pollard, Tom and Mark, Roger},
 date = {2020},
 title = {MIMIC-III Clinical Database},
 publisher = {PhysioNet},
 doi = {10.13026/C2XW26}
}


@article{Hulsen.2019,
 abstract = {For over a decade the term {\textquotedbl}Big data{\textquotedbl} has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, {\textquotedbl}Big data{\textquotedbl} no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as {\textquotedbl}data analytics{\textquotedbl} and {\textquotedbl}data science{\textquotedbl} have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises {\textquotedbl}Big Advances,{\textquotedbl} significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set {\textquotedbl}Big data{\textquotedbl} analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.},
 author = {Hulsen, Tim and Jamuar, Saumya S. and Moody, Alan R. and Karnes, Jason H. and Varga, Orsolya and Hedensted, Stine and Spreafico, Roberto and Hafler, David A. and McKinney, Eoin F.},
 year = {2019},
 title = {From Big Data to Precision Medicine},
 pages = {34},
 volume = {6},
 issn = {2296-858X},
 journal = {Frontiers in medicine},
 doi = {10.3389/fmed.2019.00034},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/30881956},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6405506}
}


@article{Yoon.2017,
 abstract = {Understanding complex relationships among heterogeneous biological data is one of the fundamental goals in biology. In most cases, diverse biological data are stored in relational databases, such as MySQL and Oracle, which store data in multiple tables and then infer relationships by multiple-join statements. Recently, a new type of database, called the graph-based database, was developed to natively represent various kinds of complex relationships, and it is widely used among computer science communities and IT industries. Here, we demonstrate the feasibility of using a graph-based database for complex biological relationships by comparing the performance between MySQL and Neo4j, one of the most widely used graph databases. We collected various biological data (protein-protein interaction, drug-target, gene-disease, etc.) from several existing sources, removed duplicate and redundant data, and finally constructed a graph database containing 114,550 nodes and 82,674,321 relationships. When we tested the query execution performance of MySQL versus Neo4j, we found that Neo4j outperformed MySQL in all cases. While Neo4j exhibited a very fast response for various queries, MySQL exhibited latent or unfinished responses for complex queries with multiple-join statements. These results show that using graph-based databases, such as Neo4j, is an efficient way to store complex biological relationships. Moreover, querying a graph database in diverse ways has the potential to reveal novel relationships among heterogeneous biological data.},
 author = {Yoon, Byoung-Ha and Kim, Seon-Kyu and Kim, Seon-Young},
 year = {2017},
 title = {Use of Graph Database for the Integration of Heterogeneous Biological Data},
 pages = {19--27},
 volume = {15},
 number = {1},
 issn = {1598-866X},
 journal = {Genomics {\&} informatics},
 doi = {10.5808/GI.2017.15.1.19},
 file = {Yoon, Kim et al. 2017 - Use of Graph Database:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Yoon, Kim et al. 2017 - Use of Graph Database.pdf:pdf}
}


@article{Himmelstein.2017,
 abstract = {The ability to computationally predict whether a compound treats a disease would improve the economy and success rate of drug approval. This study describes Project Rephetio to systematically model drug efficacy based on 755 existing treatments. First, we constructed Hetionet (neo4j.het.io), an integrative network encoding knowledge from millions of biomedical studies. Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data were integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms. Next, we identified network patterns that distinguish treatments from non-treatments. Then, we predicted the probability of treatment for 209,168 compound-disease pairs (het.io/repurpose). Our predictions validated on two external sets of treatment and provided pharmacological insights on epilepsy, suggesting they will help prioritize drug repurposing candidates. This study was entirely open and received realtime feedback from 40 community members.},
 author = {Himmelstein, Daniel Scott and Lizee, Antoine and Hessler, Christine and Brueggeman, Leo and Chen, Sabrina L. and Hadley, Dexter and Green, Ari and Khankhanian, Pouya and Baranzini, Sergio E.},
 year = {2017},
 title = {Systematic integration of biomedical knowledge prioritizes drugs for repurposing},
 volume = {6},
 journal = {eLife},
 doi = {10.7554/eLife.26726},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28936969}
}


@article{Heer.2010,
 author = {Heer, Jeffrey and Bostock, Michael and Ogievetsky, Vadim},
 year = {2010},
 title = {A tour through the visualization zoo},
 pages = {59--67},
 volume = {53},
 number = {6},
 issn = {0001-0782},
 journal = {Communications of the ACM},
 doi = {10.1145/1743546.1743567},
 file = {Heer, Bostock et al. 2010 - A tour through the visualization:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Heer, Bostock et al. 2010 - A tour through the visualization.pdf:pdf}
}


@article{Gotz.2016,
 abstract = {The healthcare industry's widespread digitization efforts are reshaping one of the largest sectors of the world's economy. This transformation is enabling systems that promise to use ever-improving data-driven evidence to help doctors make more precise diagnoses, institutions identify at risk patients for intervention, clinicians develop more personalized treatment plans, and researchers better understand medical outcomes within complex patient populations. Given the scale and complexity of the data required to achieve these goals, advanced data visualization tools have the potential to play a critical role. This article reviews a number of visualization challenges unique to the healthcare discipline.},
 author = {Gotz, David and Borland, David},
 year = {2016},
 title = {Data-Driven Healthcare: Challenges and Opportunities for Interactive Visualization},
 pages = {90--96},
 volume = {36},
 number = {3},
 journal = {IEEE computer graphics and applications},
 doi = {10.1109/MCG.2016.59},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28113160}
}


@article{Golub.2010,
 author = {Golub, Todd},
 year = {2010},
 title = {Counterpoint: Data first},
 pages = {679},
 volume = {464},
 number = {7289},
 journal = {Nature},
 doi = {10.1038/464679a},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/20360719}
}


@article{Fette.2019,
 abstract = {The Clinical Quality Language (CQL) is a useful tool for defining search requests for data stores containing FHIR data. Unfortunately, there are only few execution engines that are able to evaluate CQL queries. As FHIR data represents a graph structure, the authors pursue the approach of storing all data contained in a FHIR server in the graph database Neo4J and to translate CQL queries into Neo4J's query language Cypher. The query results returned by the graph database are retranslated into their FHIR representation and returned to the querying user. The approach has been positively tested on publicly available FHIR servers with a handcrafted set of example CQL queries.},
 author = {Fette, Georg and Kaspar, Mathias and Liman, Leon and Ertl, Maximilian and Krebs, Jonathan and St{\"o}rk, Stefan and Puppe, Frank},
 year = {2019},
 title = {Implementation of a HL7-CQL Engine Using the Graph Database Neo4J},
 pages = {46--51},
 volume = {267},
 journal = {Studies in health technology and informatics},
 doi = {10.3233/SHTI190804},
 file = {Fette, Kaspar et al. 2019 - Implementation of a HL7-CQL Engine:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Fette, Kaspar et al. 2019 - Implementation of a HL7-CQL Engine.pdf:pdf}
}


@article{Fabregat.2018,
 abstract = {Reactome is a free, open-source, open-data, curated and peer-reviewed knowledgebase of biomolecular pathways. One of its main priorities is to provide easy and efficient access to its high quality curated data. At present, biological pathway databases typically store their contents in relational databases. This limits access efficiency because there are performance issues associated with queries traversing highly interconnected data. The same data in a graph database can be queried more efficiently. Here we present the rationale behind the adoption of a graph database (Neo4j) as well as the new ContentService (REST API) that provides access to these data. The Neo4j graph database and its query language, Cypher, provide efficient access to the complex Reactome data model, facilitating easy traversal and knowledge discovery. The adoption of this technology greatly improved query efficiency, reducing the average query time by 93{\%}. The web service built on top of the graph database provides programmatic access to Reactome data by object oriented queries, but also supports more complex queries that take advantage of the new underlying graph-based data storage. By adopting graph database technology we are providing a high performance pathway data resource to the community. The Reactome graph database use case shows the power of NoSQL database engines for complex biological data types.},
 author = {Fabregat, Antonio and Korninger, Florian and Viteri, Guilherme and Sidiropoulos, Konstantinos and Marin-Garcia, Pablo and Ping, Peipei and Wu, Guanming and Stein, Lincoln and D'Eustachio, Peter and Hermjakob, Henning},
 year = {2018},
 title = {Reactome graph database: Efficient access to complex pathway data},
 pages = {e1005968},
 volume = {14},
 number = {1},
 journal = {PLoS computational biology},
 doi = {10.1371/journal.pcbi.1005968.},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5805351},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/29377902}
}


@article{Cirillo.2019,
 abstract = {Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.},
 author = {Cirillo, Davide and Valencia, Alfonso},
 year = {2019},
 title = {Big data analytics for personalized medicine},
 pages = {161--167},
 volume = {58},
 journal = {Current opinion in biotechnology},
 doi = {10.1016/j.copbio.2019.03.004},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/30965188}
}


@article{Himmelstein.2015,
 abstract = {The first decade of Genome Wide Association Studies (GWAS) has uncovered a wealth of disease-associated variants. Two important derivations will be the translation of this information into a multiscale understanding of pathogenic variants and leveraging existing data to increase the power of existing and future studies through prioritization. We explore edge prediction on heterogeneous networks--graphs with multiple node and edge types--for accomplishing both tasks. First we constructed a network with 18 node types--genes, diseases, tissues, pathophysiologies, and 14 MSigDB (molecular signatures database) collections--and 19 edge types from high-throughput publicly-available resources. From this network composed of 40,343 nodes and 1,608,168 edges, we extracted features that describe the topology between specific genes and diseases. Next, we trained a model from GWAS associations and predicted the probability of association between each protein-coding gene and each of 29 well-studied complex diseases. The model, which achieved 132-fold enrichment in precision at 10{\%} recall, outperformed any individual domain, highlighting the benefit of integrative approaches. We identified pleiotropy, transcriptional signatures of perturbations, pathways, and protein interactions as influential mechanisms explaining pathogenesis. Our method successfully predicted the results (with AUROC = 0.79) from a withheld multiple sclerosis (MS) GWAS despite starting with only 13 previously associated genes. Finally, we combined our network predictions with statistical evidence of association to propose four novel MS genes, three of which (JAK2, REL, RUNX3) validated on the masked GWAS. Furthermore, our predictions provide biological support highlighting REL as the causal gene within its gene-rich locus. Users can browse all predictions online (http://het.io). Heterogeneous network edge prediction effectively prioritized genetic associations and provides a powerful new approach for data integration across multiple domains.},
 author = {Himmelstein, Daniel S. and Baranzini, Sergio E.},
 year = {2015},
 title = {Heterogeneous Network Edge Prediction: A Data Integration Approach to Prioritize Disease-Associated Genes},
 pages = {e1004259},
 volume = {11},
 number = {7},
 journal = {PLoS computational biology},
 doi = {10.1371/journal.pcbi.1004259.},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/26158728},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4497619}
}


@article{Yoon.2017b,
 abstract = {Understanding complex relationships among heterogeneous biological data is one of the fundamental goals in biology. In most cases, diverse biological data are stored in relational databases, such as MySQL and Oracle, which store data in multiple tables and then infer relationships by multiple-join statements. Recently, a new type of database, called the graph-based database, was developed to natively represent various kinds of complex relationships, and it is widely used among computer science communities and IT industries. Here, we demonstrate the feasibility of using a graph-based database for complex biological relationships by comparing the performance between MySQL and Neo4j, one of the most widely used graph databases. We collected various biological data (protein-protein interaction, drug-target, gene-disease, etc.) from several existing sources, removed duplicate and redundant data, and finally constructed a graph database containing 114,550 nodes and 82,674,321 relationships. When we tested the query execution performance of MySQL versus Neo4j, we found that Neo4j outperformed MySQL in all cases. While Neo4j exhibited a very fast response for various queries, MySQL exhibited latent or unfinished responses for complex queries with multiple-join statements. These results show that using graph-based databases, such as Neo4j, is an efficient way to store complex biological relationships. Moreover, querying a graph database in diverse ways has the potential to reveal novel relationships among heterogeneous biological data.},
 author = {Yoon, Byoung-Ha and Kim, Seon-Kyu and Kim, Seon-Young},
 year = {2017},
 title = {Use of Graph Database for the Integration of Heterogeneous Biological Data},
 pages = {19--27},
 volume = {15},
 number = {1},
 issn = {1598-866X},
 journal = {Genomics {\&} informatics},
 doi = {10.5808/gi.2017.15.1.19.},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28416946},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5389944}
}
% This file was created with Citavi 6.7.0.0

@article{Murdoch.2013,
 author = {Murdoch, Travis B. and Detsky, Allan S.},
 year = {2013},
 title = {The Inevitable Application of Big Data to Health Care},
 pages = {1351},
 volume = {309},
 number = {13},
 issn = {0098-7484},
 journal = {JAMA},
 doi = {10.1001/jama.2013.393},
 file = {Murdoch, Detsky 2013 - The Inevitable Application of Big:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Murdoch, Detsky 2013 - The Inevitable Application of Big.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0

@article{Johnson.2016,
 abstract = {MIMIC-III ('Medical Information Mart for Intensive Care') is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
 author = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-Wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G.},
 year = {2016},
 title = {MIMIC-III, a freely accessible critical care database},
 pages = {160035},
 volume = {3},
 journal = {Scientific data},
 doi = {10.1038/sdata.2016.35},
 file = {Johnson, Pollard et al. 2016 - MIMIC-III, a freely accessible critical:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Johnson, Pollard et al. 2016 - MIMIC-III, a freely accessible critical.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0

@article{Ko.2017,
 abstract = {Objectives

Big data analysis is receiving increasing attention in many industries, including healthcare. Visualization plays an important role not only in intuitively showing the results of data analysis but also in the whole process of collecting, cleaning, analyzing, and sharing data. This paper presents a procedure for the interactive visualization and analysis of healthcare data using Tableau as a business intelligence tool.

Methods

Starting with installation of the Tableau Desktop Personal version 10.3, this paper describes the process of understanding and visualizing healthcare data using an example. The example data of colon cancer patients were obtained from health insurance claims in years 2012 and 2013, provided by the Health Insurance Review and Assessment Service.

Results

To explore the visualization of healthcare data using Tableau for beginners, this paper describes the creation of a simple view for the average length of stay of colon cancer patients. Since Tableau provides various visualizations and customizations, the level of analysis can be increased with small multiples, view filtering, mark cards, and Tableau charts.

Conclusions

Tableau is a software that can help users explore and understand their data by creating interactive visualizations. The software has the advantages that it can be used in conjunction with almost any database, and it is easy to use by dragging and dropping to create an interactive visualization expressing the desired format.},
 author = {Ko, Inseok and Chang, Hyejung},
 year = {2017},
 title = {Interactive Visualization of Healthcare Data Using Tableau},
 pages = {349--354},
 volume = {23},
 number = {4},
 issn = {2093-3681},
 journal = {Healthcare informatics research},
 doi = {10.4258/hir.2017.23.4.349},
 file = {Ko, Chang 2017 - Interactive Visualization of Healthcare Data:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Ko, Chang 2017 - Interactive Visualization of Healthcare Data.pdf:pdf}
}

% This file was created with Citavi 6.7.0.0

@article{Harris.2016,
 abstract = {We introduce a tool that extracts clinical data sets and provides visualizations from clinical data warehouses that use the Informatics for Integrating Biology and the Bedside (i2b2) query tool. Our tool, i2b2t2 (i2b2 to Tableau), can extract and visualize any i2b2 query into a portable format that researchers can easily explore without needing a highly technical or statistical background. This user-friendly format provides a quick visual summary of the queried population and is easily extendable to develop more intricate and robust visualizations. Extraction and visualization can be provided as a service by clinical data warehouses to expedite the release of data sets for research. i2b2t2 also encourages visualization as a self-service; a motivated researcher can develop custom visualizations for exploration or publication.},
 author = {Harris, Daniel R. and Henderson, Darren W.},
 year = {2016},
 title = {i2b2t2: Unlocking Visualization for Clinical Research},
 pages = {98--104},
 volume = {2016},
 journal = {AMIA Summits on Translational Science Proceedings},
 file = {Harris, Henderson 2016 - i2b2t2 Unlocking Visualization for Clinical:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Harris, Henderson 2016 - i2b2t2 Unlocking Visualization for Clinical.pdf:pdf}
}


% This file was created with Citavi 6.7.0.0

@article{Murphy.2014,
 abstract = {INTRODUCTION

A visible example of a successfully disseminated research project in the healthcare space is Informatics for Integrating Biology and the Bedside, or i2b2. The project serves to provide the software that can allow a researcher to do direct, self-serve queries against the electronic healthcare data form a hospital. The goals of these queries are to find cohorts of patients that fit specific profiles, while providing for patient privacy and discretion. Sustaining this resource and keeping its direction has always been a challenge, but ever more so as the ten year National Centers for Biomedical Computing (NCBCs) sunset their funding.

FINDINGS

Building on the i2b2 structures has helped the dissemination plans for grants leveraging it because it is a disseminated national resource. While this has not directly increased the support of i2b2 internally, it has increased the ability of institutions to leverage the resource and generally leads to increased institutional support.

DISCUSSION

The successful development, use, and dissemination i2b2 has been significant in clinical research and informatics. Its evolution has been from a local research data infrastructure to one disseminated more broadly than any other product of the National Centers for Biomedical Computing, and an infrastructure spawning larger investments than were originally used to create it. Throughout this, there were two main lessons about the benefits of dissemination: that people have great creativity in utilizing a resource in different ways and that broader system use can make the system more robust. One option for long-term sustainability of the central authority would be to translate the function to an industry partner. Another option currently being pursued is to create a foundation that would be a central authority for the project.

CONCLUSION

Over the past 10 years, i2b2 has risen to be an important staple in the toolkit of health care researchers. There are now over 110 hospitals that use i2b2 for research. This open-source platform has a community of developers that are continuously enhancing the analytic capacities of the platform and inventing new functionality. By understanding how i2b2 has been sustained, we hope that other research infrastructure projects may better navigate options in making those initiatives sustainable over time.},
 author = {Murphy, Shawn and Wilcox, Adam},
 year = {2014},
 title = {Mission and Sustainability of Informatics for Integrating Biology and the Bedside (i2b2)},
 pages = {1074},
 volume = {2},
 number = {2},
 issn = {2327-9214},
 journal = {EGEMS (Washington, DC)},
 doi = {10.13063/2327-9214.1074},
 file = {Murphy, Wilcox 2014 - Mission and Sustainability of Informatics:C\:\\Users\\k538d\\Documents\\Citavi 6\\Projects\\gmds_visual_exanimation\\Citavi Attachments\\Murphy, Wilcox 2014 - Mission and Sustainability of Informatics.pdf:pdf}
}



% This file was created with Citavi 6.7.0.0

@inproceedings{Dwivedi.18.03.201619.03.2016,
 author = {Dwivedi, Shraddha and Kasliwal, Paridhi and Soni, Suryakant},
 title = {Comprehensive study of data analytics tools (RapidMiner, Weka, R tool, Knime)},
 pages = {1--8},
 publisher = {IEEE},
 isbn = {978-1-5090-0669-4},
 booktitle = {2016 Symposium on Colossal Data Analysis and Networking (CDAN)},
 year = {18.03.2016 - 19.03.2016},
 doi = {10.1109/CDAN.2016.7570894},
 file = {http://ieeexplore.ieee.org/document/7570894/}
}








